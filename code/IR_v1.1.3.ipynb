{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport os\nimport random\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\nfrom sklearn.metrics import confusion_matrix\nfrom PIL import Image\n\ntfk = tf.keras\ntfkl = tf.keras.layers","metadata":{"papermill":{"duration":5.932547,"end_time":"2022-11-19T18:43:17.616016","exception":false,"start_time":"2022-11-19T18:43:11.683469","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-11-23T19:58:58.574524Z","iopub.execute_input":"2022-11-23T19:58:58.574952Z","iopub.status.idle":"2022-11-23T19:58:58.581884Z","shell.execute_reply.started":"2022-11-23T19:58:58.574915Z","shell.execute_reply":"2022-11-23T19:58:58.580889Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# Random seed for reproducibility\nseed = 42\n\nrandom.seed(seed)\nos.environ['PYTHONHASHSEED'] = str(seed)\nnp.random.seed(seed)\ntf.random.set_seed(seed)\ntf.compat.v1.set_random_seed(seed)","metadata":{"papermill":{"duration":0.012832,"end_time":"2022-11-19T18:43:17.633165","exception":false,"start_time":"2022-11-19T18:43:17.620333","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-11-23T19:59:04.076880Z","iopub.execute_input":"2022-11-23T19:59:04.077248Z","iopub.status.idle":"2022-11-23T19:59:04.087561Z","shell.execute_reply.started":"2022-11-23T19:59:04.077217Z","shell.execute_reply":"2022-11-23T19:59:04.086436Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"import warnings\nimport logging\n\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nwarnings.simplefilter(action='ignore', category=Warning)\ntf.get_logger().setLevel('INFO')\ntf.autograph.set_verbosity(0)\n\ntf.get_logger().setLevel(logging.ERROR)\ntf.get_logger().setLevel('ERROR')\ntf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)","metadata":{"papermill":{"duration":0.013737,"end_time":"2022-11-19T18:43:17.650834","exception":false,"start_time":"2022-11-19T18:43:17.637097","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-11-23T19:59:05.310428Z","iopub.execute_input":"2022-11-23T19:59:05.310844Z","iopub.status.idle":"2022-11-23T19:59:05.318317Z","shell.execute_reply.started":"2022-11-23T19:59:05.310816Z","shell.execute_reply":"2022-11-23T19:59:05.316863Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"## Importing data","metadata":{"papermill":{"duration":0.003744,"end_time":"2022-11-19T18:43:17.658463","exception":false,"start_time":"2022-11-19T18:43:17.654719","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Dataset folders \ndataset_dir = '/kaggle/input/an2dl-challenge-1-nt/data_splitted_no_test'\ntraining_dir = os.path.join(dataset_dir, 'train')\nvalidation_dir = os.path.join(dataset_dir, 'val')","metadata":{"papermill":{"duration":0.010968,"end_time":"2022-11-19T18:43:17.673636","exception":false,"start_time":"2022-11-19T18:43:17.662668","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-11-23T19:59:06.616954Z","iopub.execute_input":"2022-11-23T19:59:06.617346Z","iopub.status.idle":"2022-11-23T19:59:06.622576Z","shell.execute_reply.started":"2022-11-23T19:59:06.617313Z","shell.execute_reply":"2022-11-23T19:59:06.621377Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"# Images are divided into folders, one for each class. \n# If the images are organized in such a way, we can exploit the \n# ImageDataGenerator to read them from disk.\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Create an instance of ImageDataGenerator, and for the trainign with Data Augmentation\ntrain_data_gen = ImageDataGenerator(rotation_range=30, \n                                    height_shift_range=0.2, \n                                    width_shift_range=0.2, \n                                    zoom_range=0.2, \n                                    horizontal_flip=True, \n                                    shear_range=0.2, \n                                    fill_mode='reflect',\n                                    rescale=1/255.) # rescale value is multiplied to the image ############################################\nvalid_data_gen = ImageDataGenerator(rescale=1/255.)\n\n# Obtain a data generator with the 'ImageDataGenerator.flow_from_directory' method\ntrain_gen = train_data_gen.flow_from_directory(directory=training_dir,\n                                                       target_size=(96,96),\n                                                       color_mode='rgb',\n                                                       classes=None, # can be set to labels\n                                                       class_mode='categorical',\n                                                       batch_size=8,\n                                                       shuffle=True,\n                                                       seed=seed)\n\nvalid_gen = valid_data_gen.flow_from_directory(directory=validation_dir,\n                                               target_size=(96,96),\n                                               color_mode='rgb',\n                                               classes=None, # can be set to labels\n                                               class_mode='categorical',\n                                               batch_size=8,\n                                               shuffle=False,\n                                               seed=seed)","metadata":{"papermill":{"duration":0.436165,"end_time":"2022-11-19T18:43:18.113689","exception":false,"start_time":"2022-11-19T18:43:17.677524","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-11-23T19:59:07.902511Z","iopub.execute_input":"2022-11-23T19:59:07.903326Z","iopub.status.idle":"2022-11-23T19:59:08.140778Z","shell.execute_reply.started":"2022-11-23T19:59:07.903285Z","shell.execute_reply":"2022-11-23T19:59:08.139748Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"Found 3648 images belonging to 8 classes.\nFound 648 images belonging to 8 classes.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Model","metadata":{"papermill":{"duration":0.003921,"end_time":"2022-11-19T18:43:18.122009","exception":false,"start_time":"2022-11-19T18:43:18.118088","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import os\nos.listdir(\"/kaggle/input/ir-v104/IR_v1.0.4\")","metadata":{"execution":{"iopub.status.busy":"2022-11-23T19:59:09.723819Z","iopub.execute_input":"2022-11-23T19:59:09.724396Z","iopub.status.idle":"2022-11-23T19:59:09.742091Z","shell.execute_reply.started":"2022-11-23T19:59:09.724365Z","shell.execute_reply":"2022-11-23T19:59:09.741395Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"['variables', 'saved_model.pb', 'keras_metadata.pb']"},"metadata":{}}]},{"cell_type":"code","source":"# Re-load the model after transfer learning\nIR = tfk.models.load_model('/kaggle/input/ir-v104/IR_v1.0.4')\nIR.summary()","metadata":{"execution":{"iopub.status.busy":"2022-11-23T19:59:11.493933Z","iopub.execute_input":"2022-11-23T19:59:11.494624Z","iopub.status.idle":"2022-11-23T19:59:56.197910Z","shell.execute_reply.started":"2022-11-23T19:59:11.494586Z","shell.execute_reply":"2022-11-23T19:59:56.196928Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_layer (InputLayer)     [(None, 96, 96, 3)]       0         \n_________________________________________________________________\ninception_resnet_v2 (Functio (None, 1, 1, 1536)        54336736  \n_________________________________________________________________\nglobal_average_pooling2d (Gl (None, 1536)              0         \n_________________________________________________________________\ndropout (Dropout)            (None, 1536)              0         \n_________________________________________________________________\nClassifier1 (Dense)          (None, 512)               786944    \n_________________________________________________________________\nactivation_203 (Activation)  (None, 512)               0         \n_________________________________________________________________\nbatch_normalization_203 (Bat (None, 512)               2048      \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 512)               0         \n_________________________________________________________________\nClassifier2 (Dense)          (None, 60)                30780     \n_________________________________________________________________\nactivation_204 (Activation)  (None, 60)                0         \n_________________________________________________________________\nbatch_normalization_204 (Bat (None, 60)                240       \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 60)                0         \n_________________________________________________________________\noutput_layer (Dense)         (None, 8)                 488       \n=================================================================\nTotal params: 55,157,236\nTrainable params: 55,095,548\nNon-trainable params: 61,688\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"IR.trainable = False","metadata":{"execution":{"iopub.status.busy":"2022-11-23T20:00:39.946158Z","iopub.execute_input":"2022-11-23T20:00:39.946592Z","iopub.status.idle":"2022-11-23T20:00:39.984433Z","shell.execute_reply.started":"2022-11-23T20:00:39.946558Z","shell.execute_reply":"2022-11-23T20:00:39.983304Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"IR_2 = tfk.models.Sequential(IR.layers[:-11])","metadata":{"execution":{"iopub.status.busy":"2022-11-23T20:00:51.161092Z","iopub.execute_input":"2022-11-23T20:00:51.161488Z","iopub.status.idle":"2022-11-23T20:00:52.436077Z","shell.execute_reply.started":"2022-11-23T20:00:51.161454Z","shell.execute_reply":"2022-11-23T20:00:52.435020Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"IR_2.summary()","metadata":{"execution":{"iopub.status.busy":"2022-11-23T20:00:53.290127Z","iopub.execute_input":"2022-11-23T20:00:53.290527Z","iopub.status.idle":"2022-11-23T20:00:53.340858Z","shell.execute_reply.started":"2022-11-23T20:00:53.290495Z","shell.execute_reply":"2022-11-23T20:00:53.339234Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"Model: \"sequential_5\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninception_resnet_v2 (Functio (None, 1, 1, 1536)        54336736  \n=================================================================\nTotal params: 54,336,736\nTrainable params: 0\nNon-trainable params: 54,336,736\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"input_shape = (96, 96, 3)\nepochs = 200","metadata":{"execution":{"iopub.status.busy":"2022-11-23T20:00:56.316171Z","iopub.execute_input":"2022-11-23T20:00:56.316584Z","iopub.status.idle":"2022-11-23T20:00:56.321943Z","shell.execute_reply.started":"2022-11-23T20:00:56.316551Z","shell.execute_reply":"2022-11-23T20:00:56.320937Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"def inceptionresnetv2_2(input_shape):\n\n    # Build the neural network layer by layer\n    input_layer_2 = tfkl.Input(shape=input_shape, name='input_layer')\n    \n    #x = tfkl.Resizing(64, 64, interpolation=\"bicubic\", name='resizing')(input_layer)\n    ir_2 = IR_2(input_layer_2)\n\n    gap = tfkl.GlobalAveragePooling2D()(ir_2)\n    drop1 = tfkl.Dropout(0.4, seed=seed)(gap)\n    classifier_layer1 = tfkl.Dense(units=512, name='Classifier1', kernel_initializer=tfk.initializers.HeUniform(seed), activation='relu')(drop1)\n    drop2 = tfkl.Dropout(0.4, seed=seed)(classifier_layer1)\n    output_layer = tfkl.Dense(units=8, activation='softmax', kernel_initializer=tfk.initializers.GlorotUniform(seed), name='output_layer')(drop2)\n    # Connect input and output through the Model class\n    model = tfk.Model(inputs=input_layer_2, outputs=output_layer, name='model')\n\n    # Compile the model\n    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.RMSprop(learning_rate=0.001), metrics='accuracy')\n\n    # Return the model\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-11-23T20:00:57.888870Z","iopub.execute_input":"2022-11-23T20:00:57.889260Z","iopub.status.idle":"2022-11-23T20:00:57.897366Z","shell.execute_reply.started":"2022-11-23T20:00:57.889228Z","shell.execute_reply":"2022-11-23T20:00:57.896459Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"# Build model\nIR_final = inceptionresnetv2_2(input_shape)\nIR_final.summary()","metadata":{"execution":{"iopub.status.busy":"2022-11-23T20:00:59.406398Z","iopub.execute_input":"2022-11-23T20:00:59.407122Z","iopub.status.idle":"2022-11-23T20:01:03.440009Z","shell.execute_reply.started":"2022-11-23T20:00:59.407085Z","shell.execute_reply":"2022-11-23T20:01:03.439218Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_layer (InputLayer)     [(None, 96, 96, 3)]       0         \n_________________________________________________________________\nsequential_5 (Sequential)    (None, 1, 1, 1536)        54336736  \n_________________________________________________________________\nglobal_average_pooling2d_2 ( (None, 1536)              0         \n_________________________________________________________________\ndropout_6 (Dropout)          (None, 1536)              0         \n_________________________________________________________________\nClassifier1 (Dense)          (None, 512)               786944    \n_________________________________________________________________\ndropout_7 (Dropout)          (None, 512)               0         \n_________________________________________________________________\noutput_layer (Dense)         (None, 8)                 4104      \n=================================================================\nTotal params: 55,127,784\nTrainable params: 791,048\nNon-trainable params: 54,336,736\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# Train the model\nIR_history = IR_final.fit(\n    x = train_gen,\n    batch_size = 256,\n    epochs = 200,\n    validation_data = valid_gen,\n    callbacks = [tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=20, restore_best_weights=True)],\n).history","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the best model\nIR_final.save('IR_v1.1.3')","metadata":{"papermill":{"duration":79.107029,"end_time":"2022-11-19T19:07:12.764244","exception":false,"start_time":"2022-11-19T19:05:53.657215","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the training\nplt.figure(figsize=(15,5))\nplt.plot(IR_history['loss'], alpha=.3, color='#ff7f0e', linestyle='--')\nplt.plot(IR_history['val_loss'], label='Standard', alpha=.8, color='#ff7f0e')\nplt.legend(loc='upper left')\nplt.title('Categorical Crossentropy')\nplt.grid(alpha=.3)\nplt.savefig('IR_v1.1.3_loss.png')\n\nplt.figure(figsize=(15,5))\nplt.plot(IR_history['accuracy'], alpha=.3, color='#ff7f0e', linestyle='--')\nplt.plot(IR_history['val_accuracy'], label='Standard', alpha=.8, color='#ff7f0e')\nplt.legend(loc='upper left')\nplt.title('Accuracy')\nplt.grid(alpha=.3)\nplt.savefig('IR_v1.1.3_acc.png')\n\nplt.show()","metadata":{"papermill":{"duration":1.264347,"end_time":"2022-11-19T19:05:52.888502","exception":false,"start_time":"2022-11-19T19:05:51.624155","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate on val\nval_metrics = IR_final.evaluate(valid_gen, return_dict=True)\n\nprint()\nprint(\"Val metrics\")\nprint(val_metrics)","metadata":{"papermill":{"duration":3.43052,"end_time":"2022-11-19T19:07:17.344516","exception":false,"start_time":"2022-11-19T19:07:13.913996","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}