{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Manage the directories","metadata":{}},{"cell_type":"code","source":"# Not important\nimport os\nos.listdir(\"../input/slitted-dataset-notest-v1/splitted_dataset_noTest\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# To delete a folder\nimport shutil\nif os.path.exists(\"/kaggle/working/nicholas\"):\n    shutil.rmtree(\"/kaggle/working/nicholas\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# to remove a file\nimport os\nif os.path.exists(\"/kaggle/working/model.png\"):\n    os.remove(\"/kaggle/working/model.png\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# to create a folder\nimport os\ndirectory = \"DenseNet201\"\nparent_dir = \"/kaggle/working\"\npath = os.path.join(parent_dir, directory)\nif not os.path.exists(path):\n    os.mkdir(path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# make a folder zip file and downloadable\n#import shutil\n#shutil.make_archive(\"kaggle_model2\", 'zip', \"/kaggle/working\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Operations","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport os\nimport random\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\nfrom sklearn.metrics import confusion_matrix\nfrom PIL import Image\n\ntfk = tf.keras\ntfkl = tf.keras.layers","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random seed for reproducibility\nseed = 42\n\nrandom.seed(seed)\nos.environ['PYTHONHASHSEED'] = str(seed)\nnp.random.seed(seed)\ntf.random.set_seed(seed)\ntf.compat.v1.set_random_seed(seed)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nimport logging\n\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nwarnings.simplefilter(action='ignore', category=Warning)\ntf.get_logger().setLevel('INFO')\ntf.autograph.set_verbosity(0)\n\ntf.get_logger().setLevel(logging.ERROR)\ntf.get_logger().setLevel('ERROR')\ntf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Importing data","metadata":{}},{"cell_type":"code","source":"# Dataset folders \ndataset_dir = '../input/splitted-dataset/splitted_dataset'\ntraining_dir = os.path.join(dataset_dir, 'train')\nvalidation_dir = os.path.join(dataset_dir, 'val')\n#test_dir = os.path.join(dataset_dir, 'test')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_height = 96\nimg_width =96\nbatch_size = 32","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Images are divided into folders, one for each class. \n# If the images are organized in such a way, we can exploit the \n# ImageDataGenerator to read them from disk.\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Create an instance of ImageDataGenerator, and for the trainign with Data Augmentation\ntrain_data_gen = ImageDataGenerator(rotation_range=30,\n                                        height_shift_range=50,\n                                        width_shift_range=50,\n                                        zoom_range=0.3,\n                                        horizontal_flip=True, \n                                        fill_mode='reflect')\n\n# Obtain a data generator with the 'ImageDataGenerator.flow_from_directory' method\ntrain_gen = train_data_gen.flow_from_directory(directory=training_dir,\n                                                       target_size=(96,96),\n                                                       color_mode='rgb',\n                                                       classes=None, # can be set to labels\n                                                       class_mode='categorical',\n                                                       batch_size=8,\n                                                       shuffle=True,\n                                                       seed=seed)\n\nvalid_gen = train_data_gen.flow_from_directory(directory=validation_dir,\n                                               target_size=(96,96),\n                                               color_mode='rgb',\n                                               classes=None, # can be set to labels\n                                               class_mode='categorical',\n                                               batch_size=8,\n                                               shuffle=False,\n                                               seed=seed)\n\"\"\"\ntest_gen = train_data_gen.flow_from_directory(directory=test_dir,\n                                              target_size=(96,96),\n                                              color_mode='rgb',\n                                              classes=None, # can be set to labels\n                                              class_mode='categorical',\n                                              batch_size=8,\n                                              shuffle=False,\n                                              seed=seed)\n\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_next_batch(generator):\n  batch = next(generator)# we get the next batch(a list of two elements: image and target)\n\n  image = batch[0]\n  target = batch[1]\n\n  print(\"(Input) image shape:\", image.shape)\n  print(\"Target shape:\",target.shape)\n\n  # Visualize only the first sample\n  image = image[0]\n  target = target[0]\n  target_idx = np.argmax(target)\n  print()\n  print(\"Categorical label:\", target)\n  print(\"Label:\", target_idx)\n  print(\"Class name:\", labels[target_idx])\n  fig = plt.figure(figsize=(6, 4))\n  plt.imshow(np.uint8(image))\n\n  return batch","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"!cd /kaggle/working/DenseNet","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Download and plot the DenseNet model\nsupernet = tfk.applications.DenseNet201(\n    include_top=False,\n    weights=\"imagenet\",\n    input_shape=(96,96,3),\n)\nsupernet.summary()\ntfk.utils.plot_model(supernet)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_shape = (96, 96, 3)\nepochs = 200","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.python.framework.tensor_util import GetNumpyAppendFn\n\n# Use the supernet as feature extractor\nsupernet.trainable = False\n# in this way we keep the weights of the CNN part and we will train only the weights of the classifier\n\ninput_layer = tfkl.Input(shape=input_shape, name='input_layer')\n#x = tfkl.Resizing(96, 96, interpolation=\"bicubic\")(input_layer)\nx = supernet(input_layer)\nx = tfkl.Flatten(name='Flattening')(x)\nx = tfkl.Dropout(0.4, seed=seed)(x)\nx = tfkl.Dense(\n    512, \n    activation='relu',\n    kernel_initializer = tfk.initializers.HeUniform(seed))(x)\nx = tfkl.Dropout(0.4, seed=seed)(x)\noutputs = tfkl.Dense(\n    8, \n    activation='softmax',\n    kernel_initializer = tfk.initializers.GlorotUniform(seed))(x)\n\n\n# Connect input and output through the Model class\ntl_model = tfk.Model(inputs=input_layer, outputs=outputs, name='model')\n\n# Compile the model\ntl_model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\ntl_model.summary()\ntfk.utils.plot_model(tl_model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tl_model.get_layer('densenet201').trainable = True","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Freeze first N layers\nN = -226 #or | 706 total | 481 is the start of 5conv |  = 2+7xblock 481\n\nfor i, layer in enumerate(tl_model.get_layer('densenet201').layers[:N]):\n  layer.trainable=False\nfor i, layer in enumerate(tl_model.get_layer('densenet201').layers):\n   print(i, layer.name, layer.trainable)\ntl_model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compile the model\ntl_model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(1e-4), metrics='accuracy')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"patience = 15","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Utility function to create folders and callbacks for training\nfrom datetime import datetime\n\ndef create_folders_and_callbacks(model_name):\n\n  exps_dir = os.path.join('/kaggle/working/DenseNet/data_augmentation_DenseNet201')\n  if not os.path.exists(exps_dir):\n      os.makedirs(exps_dir)\n\n  now = datetime.now().strftime('%b%d_%H-%M-%S')\n\n  exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n  if not os.path.exists(exp_dir):\n      os.makedirs(exp_dir)\n      \n  callbacks = []\n\n  # Model checkpoint -> save model after each epoch\n  # ----------------\n  ckpt_dir = os.path.join(exp_dir, 'ckpts')\n  if not os.path.exists(ckpt_dir):\n      os.makedirs(ckpt_dir)\n\n  ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp.ckpt'), \n                                                     save_weights_only=True, # True to save only weights, false to save the model as we did before af the end of the training\n                                                     save_best_only=False) # True to save only the best epoch, false we save each epoch by default\n  callbacks.append(ckpt_callback)\n\n  # Visualize Learning on Tensorboard\n  # ---------------------------------\n  tb_dir = os.path.join(exp_dir, 'tb_logs')\n  if not os.path.exists(tb_dir):\n      os.makedirs(tb_dir)\n      \n  # By default shows losses and metrics for both training and validation\n  tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir, \n                                               profile_batch=0,# 0 therwise we have some problems in the visualization\n                                               histogram_freq=1)  # if > 0 (epochs) shows weights histograms\n  callbacks.append(tb_callback)\n\n  # Early Stopping\n  # --------------\n  es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=patience, restore_best_weights=True)\n  callbacks.append(es_callback)\n\n  return callbacks","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create folders and callbacks and fit\ncallbacks = create_folders_and_callbacks(model_name='DenseNet201_FineTuning')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the model\ntl_history = tl_model.fit(\n    x = train_gen,\n    batch_size = 256,\n    epochs = 200,\n    validation_data = valid_gen,\n    callbacks = callbacks,\n    #callbacks = [tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=10, restore_best_weights=True)],\n).history","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the training\nplt.figure(figsize=(15,5))\nplt.plot(tl_history['loss'], label='Training', alpha=.3, color='#4D61E2', linestyle='--')\nplt.plot(tl_history['val_loss'], label='Validation', alpha=.8, color='#4D61E2')\nplt.legend(loc='upper left')\nplt.title('Categorical Crossentropy')\nplt.grid(alpha=.3)\n\nplt.figure(figsize=(15,5))\nplt.plot(tl_history['accuracy'], label='Training',alpha=.3, color='#4D61E2', linestyle='--')\nplt.plot(tl_history['val_accuracy'], label='Validation', alpha=.8, color='#4D61E2')\nplt.legend(loc='upper left')\nplt.title('Accuracy')\nplt.grid(alpha=.3)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the best model\ntl_model.save('DenseNet201_fine_tuning')\n#del tl_model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\nshutil.make_archive(\"DenseNet201_FineTuning\", 'zip', \"/kaggle/working/DenseNet201_fine_tuning/\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}